---
layout: post
title: 操作系统
date: 2023-10-31 08:22 +0800
categories: [笔记]
tags: [操作系统]
toc:  true
---

## 1 常见Linux命令

cd ls grep wc cp mv rm ps kill tar cat top pwd

```shell
ls
    -a,--all //显示所有文件与文件夹，包括隐藏文件夹.和..
    -A,--almost-all //显示所有文件与文件夹，不包括隐藏文件夹.和..
    -B,--ignore-backups //不显示以~结尾的文件
    -h,--human-readable //显示人类可读的格式MB、GB
    -t //按照文件修改的时间排序
    -S //按照文件大小排序
    -R //递归显示文件或文件夹
    -l
grep [OPTIONS] PATTERN [FILE...]
	-i //匹配时忽略大小写
	--color=auto //对匹配到的字符做高亮显示
	-v //反向查找，只打印不匹配的行。
	//ls -l | grep "^d" | wc -l
wc 
	-c //统计字节数。
	-l //统计行数。
	-w //统计字数。
ps
	-aux //-a代表all，x参数会显示没有控制终端的进程，u CPU或者内存用量
	-ef // -e等同-A，显示进程关系
kill
	-STOP //停止一个进程，而并不linux杀死进程
	-CONT //重新开始一个停止的进程
	-9 //终止你拥有的全部进程
killall //通过程序的名字，直接杀死所有进程
free
	-m //以兆字节显示输出
	-h //显示人类可读的输出
tar
//五个命令中必选一个
     -c //建立压缩档案
     -x //解压
     -t //查看内容
     -r //向压缩归档文件末尾追加文件
     -u //更新原压缩包中的文件
//这几个参数是可选的
     -z //有gzip属性的
     -j //有bz2属性的
     -Z //有compress属性的
     -v //显示所有过程
     -O //将文件解开到标准输出
chmod [-R] xyz [file...]
	-R //进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都会变更
	xyz //数字类型的权限属性
	//文件的权限字符为 [-rwxrwx---]，owner/group/others
chown user file
ln -s log2013.log link2013 //软链接
ln log2013.log ln2013 //硬链接
```

## 2 软链接和硬链接

硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。

软链接又叫符号链接，这个文件包含了另一个文件的路径名。可以是**任意文件或目录**，可以链接不同文件系统的文件。软链接可对不存在的文件或目录创建软链接；可交叉文件系统；

硬链接就是一个**文件**的一个或多个文件名。把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。硬链接只能对**已存在的文件**进行创建，**不能交叉文件系统**进行硬链接的创建；

只删除一个硬连接并不影响索引节点本身和其它的硬连接文件真正删除的条件是与之相关的所有硬连接文件均被删除。

## 3 大端小端

**小端模式**：**低位**的有效字节存储在**低的**存储器地址。小端一般为主机字节序；常用的X86结构是小端模式。很多的ARM，DSP都为小端模式。强制转换数据不需要调整字节内容，int转char直接去掉高位。

**大端模式**：**高位**的有效字节存储在**低的**存储器地址。大端为网络字节序；KEIL C51则为大端模式。符号位的判定固定为第一个字节，容易判断正负。

| 内存地址 | 小端模式存放内容 | 大端模式存放内容|
|---|---|---|
| 0x4000 | 0x34 | 0x12 |
| 0x4001 | 0x12 | 0x34 |

我们可以根据**联合体**来判断系统是大端还是小端。因为联合体变量总是从**低地址**存储。

1. **在进行网络通信时是否需要进行字节序转换？**

相同字节序的平台在进行网络通信时可以不进行字节序转换，但是跨平台进行网络数据通信时必须进行字节序转换。原因如下：**网络协议规定接收到得第一个字节是高字节，存放到低地址，所以发送时会首先去低地址取数据的高字节**。小端模式的多字节数据在存放时，低地址存放的是低字节，网络传输字节流被**发送方网络协议函数**发送时会首先去低地址取数据（取得是低字节，想要取高字节），接收方网络协议函数接收时会将接收到的第一个字节存放到低地址（接收的是低字节，想要接收高字节），所以最后双方都正确的收发了数据。而相同平台进行通信时，如果双方都进行转换最后虽然能够正确收发数据，但是所做的转换是没有意义的，造成资源的浪费。而不同平台进行通信时必须进行转换，不转换会造成错误的收发数据，字节序转换函数会根据当前平台的存储模式做出相应正确的转换，如果当前平台是大端，则直接返回不进行转换，如果当前平台是小端，会将接收到得网络字节序进行转换。

2. UDP/TCP/IP协议规定：把接收到的第一个字节当作高位字节看待，这就要求发送端发送的第一个字节是高位字节；

## 4 进程

### 4.1 进程、线程、协程区别

**进程**：是具有一定 独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位。

**线程**：是处理器调度和分派的基本单位。一个进程里包含多个线程并发执行任务。**进程频繁切换将引起额外开销，从而严重影响系统的性能。**

**协程**是**微线程**，在子程序内部执行，可在子程序内部中断，转而执行别的子程序，在适当的时候再返回来接着执行。协程的调度完全由用户控制，协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其它地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

![](/assets/img//xiechen.png)

**线程与进程的区别**：（1）一个线程从属于一个进程；一个进程可以包含多个线程。（2）一个**线程**挂掉，对应的进程挂掉，多线程也挂掉；一个**进程**挂掉，不会影响其他进程，多进程稳定。（3）进程是系统资源调度的最小单位；线程CPU调度的最小单位。（4）进程系统开销显著大于线程开销；线程需要的系统资源更少。（5）进程在执行时拥有独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。（6）进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈，线程切换时只需要切换硬件上下文和内核栈。（7）通信方式不一样。

**线程与协程的区别：**（1）协程执行效率极高。协程直接操作栈基本没有内核切换的开销，所以上下文的切换非常快，切换开销比线程更小。（2）协程不需要多线程的锁机制，因为多个协程从属于一个线程，不存在同时写变量冲突，效率比线程高。（3）一个线程可以有多个协程。

**并发**：对于单个CPU，在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级，多个任务不停来回快速切换。**并行**：对于多个CPU，多个进程同时运行。

进程有五种状态：**创建、就绪、执行、阻塞、终止**。

![](/assets/img/thread_state_trans.png)

### 4.2 进程调度算法

1. 先来先服务调度算法
2. 短作业(进程)优先调度算法
3. 高优先级优先调度算法
4. 时间片轮转法
5. 多级反馈队列调度算法

### 4.3 进程控制

```cpp
// fork函数用于创建一个新的进程，它与原始进程具有相同的代码和数据。新进程称为子进程，
// fork()函数在子进程中返回0，在父进程中返回子进程的PID。
#include <unistd.h>
pid_t fork(void);
// exec函数用于执行一个新的程序。它将当前进程替换为一个新的进程，从而在当前进程的地址空间中加
// 载一个新的程序。有许多不同版本的exec函数，例如execvp、execlp等。
#include <unistd.h>
int execl(const char *path, const char *arg, ...);
int execlp(const char *file, const char *arg, ...);
int execv(const char *path, char *const argv[]);
int execvp(const char *file, char *const argv[]);
// wait函数用于等待子进程的终止。如果子进程已经终止，wait函数将返回子进程的PID。
// 如果子进程还没有终止，wait函数将阻塞直到子进程终止为止。
#include <sys/types.h>
#include <sys/wait.h>
pid_t wait(int *status);
pid_t waitpid(pid_t pid, int *status, int options);
// getpid函数用于获取当前进程的PID。
#include <unistd.h>
pid_t getpid(void);
// kill函数用于向进程发送信号。它接受两个参数：要发送信号的进程的PID和信号的编号。
#include <sys/types.h>
#include <signal.h>
int kill(pid_t pid, int sig);
// pipe函数用于创建一个管道，它允许两个进程之间进行通信。pipe函数返回两个文件描述符：
// 一个用于读取管道，另一个用于写入管道。
#include <unistd.h>
int pipe(int pipefd[2]);
// dup函数用于复制文件描述符。它接受一个文件描述符作为参数，
// 并返回一个新的文件描述符，该文件描述符与原始文件描述符指向相同的文件。
#include <unistd.h>
int dup(int oldfd);
// execl函数用于执行一个新的程序。
// 它接受一个程序名称和一系列参数，用于指定要执行的程序和程序的参数。
#include <unistd.h>
int execl(const char *path, const char *arg, ...);
// exit函数用于终止进程。它接受一个整数参数作为退出码，该参数将传递给父进程。
#include <stdlib.h>
void exit(int status);
```

fork函数用来 创建一个子进程。对于父进程，fork()函数返回新创建的子进程的PID。对于子进程，fork()函数调用成功会返回0。如果创建出错，fork()函数返回-1。

fork()函数创建一个新进程后，会为这个新进程分配进程空间，将父进程的进程空间中的内容复制到子进程的进程空间中，包括父进程的数据段和堆栈段，并且和父进程共享代码段。这时候，子进程和父进程一模一样，都接受系统的调度。因为两个进程都停留在fork()函数中，**一次fork返回了两次值，这时候就能够同时跑两个进程了。**

```cpp
#include <stdio.h>
#include <unistd.h>

int main(int argc,char *argv[]){
    for(int i = 0; i < 2; i++) {
        fork();
        printf("*");
    }
    return 0;
}

// output:********
// 因为在fork的时候，缓存被复制到了子进程的空间，所以多了两个。如果printf遇到"\n"或者EOF就会
// 把数据刷出缓冲区
```

**孤儿进程**：是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并且由init进程对它们完整状态收集工作。

**僵尸进程**：是指一个进程使用fork函数创建子进程，如果子进程退出，而父进程并没有调用wait()或者waitpid()系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程。

（1）一般，为了防止产生僵尸进程，在fork子进程之后我们都要及时使用**wait系统调用**；同时，当子进程退出的时候，内核都会给父进程一个SIGCHLD信号，所以我们可以建立一个捕获SIGCHLD信号的信号处理函数，在函数体中调用wait（或waitpid），就可以清理退出的子进程以达到防止僵尸进程的目的。

（2）**使用kill命令**。

```shell
ps aux | grep Z #会列出进程表中所有僵尸进程的详细内容
kill -s SIGCHLD pid(父进程pid)
```

**守护进程**：守护进程（Daemon 进程）是运行在后台的一种生存期长的特殊进程。它独立于控制终端，处理一些系统级别任务。

（1）调用fork() 产生一个子进程，然后使父进程退出。

（2）调用setsid() 创建一个新会话。进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。

（3）将当前目录更改为根目录。使用fork() 创建的子进程也继承了父进程的当前工作目录。

（4）重设文件权限掩码。文件权限掩码是指屏蔽掉文件权限中的对应位。

（5）关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。

```cpp
#include <stdio.h>  
#include <stdlib.h>  
#include <string.h>  
#include <fcntl.h>  
#include <unistd.h>  
#include <sys/wait.h>  
#include <sys/types.h>  
#include <sys/stat.h>  

#define MAXFILE 65535  

int main(){  
    //第一步:创建进程   
    int pid = fork();  
    if (pid > 0)  
        exit(0);//结束父进程   
    else if (pid < 0){  
        printf("fork error!\n");  
        exit(1);//fork失败，退出   
    }  
    //第二步:子进程成为新的会话组长和进程组长,并与控制终端分离   
    setsid();  
    //第三步:改变工作目录到  
    chdir("/");  
    //第四步:重设文件创建掩模   
    umask(0);  
    //第五步:关闭打开的文件描述符  
    for (int i=0; i<MAXFILE; ++i)   
        close(i); 
    sleep(2);    
    return 0;  
}  
```

### 4.4 进程通信

进程间通信主要包括**管道**、**系统IPC**（包括消息队列、信号量、信号、共享内存）、**套接字socket**。

1. **管道**：包括无名管道和命名管道，无名管道半双工，只能用于具有亲缘关系的进程直接的通信（父子进程或者兄弟进程），可以看作一种特殊的文件；命名管道可以允许无亲缘关系进程间的通信。
2. **系统IPC消息队列**：消息的链接表，放在内核中。消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除；消息队列可以实现消息的随机查询，可以按照消息的类型读取。**信号量semaphore**：是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步。**信号**：用于通知接收进程某个事件的发生。**内存共享**：使多个进程访问同一块内存空间。
3. **套接字socket**：用于不同主机直接的通信。

操作系统在内核中开辟一块**缓冲区**（称为**管道**）用于通信。**管道**是一种两个进程间进行**单向通信**的机制。因为这种单向性，管道又称为半双工管道，所以其使用是有一定的局限性的。半双工是指数据只能由一个进程流向另一个进程（一个管道负责读，一个管道负责写）；如果是全双工通信，需要建立两个管道。

pipe()函数创建的管道处于一个进程中间，因此一个进程在由 pipe()创建管道后，一般再使用fork() 建立一个子进程，然后通过管道实现父子进程间的通信。管道两端可分别用描述字fd[0]以及fd[1]来描述。注意管道的两端的任务是固定的，即一端只能用于读，由描述字fd[0]表示，称其为管道读端；另 一端则只能用于写，由描述字fd[1]来表示，称其为管道写端。如果试图从管道写端读取数据，或者向管道读端写入数据都将发生错误。一般文件的 I/O 函数都可以用于管道，如close()、read()、write()等。

**具体步骤**如下：

1. 父进程调用pipe开辟管道，得到两个文件描述符指向管道的两端。
2. 父进程调用fork创建子进程,那么子进程**也有两个文件描述符**指向同一管道。
3. 父进程关闭管道读端,子进程关闭管道写端。父进程可以往管道里写,子进程可以从管道里读,管道是用环形队列实现的,数据从写端流入从读端流出,这样就实现了进程间通信。

```cpp
#include<unistd.h>    
#include<stdio.h>    
#include<stdlib.h>    
#include<string.h>    
#define INPUT  0     
#define OUTPUT 1    

int main(){    
    //创建管道    
    int fd[2];    
    pipe(fd);    
    //创建子进程    
    pid_t pid = fork();    
    if (pid < 0){    
        printf("fork error!\n");    
        exit(-1);    
    }    
    else if (pid == 0){//执行子进程  
        printf("Child process is starting...\n");  
        //子进程向父进程写数据，关闭管道的读端   
        close(fd[INPUT]);  
        write(fd[OUTPUT], "hello douya!", strlen("hello douya!"));  
        exit(0);  
    }  
    else{//执行父进程  
        printf ("Parent process is starting......\n");  
        //父进程从管道读取子进程写的数据 ，关闭管道的写端    
        close(fd[OUTPUT]);    
        char buf[255];  
        int output = read(fd[INPUT], buf, sizeof(buf));  
        printf("%d bytes of data from child process: %s\n", output, buf);  
    }  
    return 0;    
}   
```

**常见信号**

| **信号代号** | **信号名称** | **说 明** |
| --- | --- | --- |
| **1** | SIGHUP | 该信号让进程立即关闭.然后重新读取配置文件之后重启 |
| **9** | SIGKILL | 用来立即结束程序的运行。本信号不能被阻塞、处理和忽略。般用于强制中止进程 |
| **15** | SIGTERM | 正常结束进程的信号，kill 命令的默认信号。如果进程已经发生了问题，那么这 个信号是无法正常中止进程的，这时我们才会尝试 SIGKILL 信号，也就是信号 9 |
| **17** | SIGCHLD | 子进程结束时, 父进程会收到这个信号。 |
| 18 | SIGCONT | 该信号可以让暂停的进程恢复执行。本信号不能被阻断 |
| 19 | SIGSTOP | 该信号可以暂停前台进程，相当于输入 Ctrl+Z 快捷键。本信号不能被阻断 |

一个进程如何handle 一个信号：

- 信号发送，由其他进程产生信号发送给目的进程（比如命令行kill -9）
- 信号保存，进程收到某种信号时并不是马上处理的，没有被立即处理的信号会被放在进程控制块中
- 信号处理，signal函数执行对应的处理函数

### 4.4 进程同步

1. **信号量semaphore**：是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步。P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。
2. **管道**：一个进程通过调用管程的一个过程进入管程。在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。
3. **消息队列**：消息的链接表，放在内核中。消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除；消息队列可以实现消息的随机查询，可以按照消息的类型读取。

信号量本质上是一个计数器，用于多进程对共享数据对象的读取，它主要是用来保护共享资源（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。（1）P(sv)操作：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行（信号量的值为正，进程获得该资源的使用权，进程将信号量减1，表示它使用了一个资源单位）。（2）V(sv)操作：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1（若此时信号量的值为0，则进程进入挂起状态，直到信号量的值大于0，若进程被唤醒则返回至第一步）。

**互斥量能在进程中使用，**不同的进程之间，存在资源竞争或并发使用的问题，所以需要**互斥量**。进程中也需要**互斥量**，因为一个进程中可以包含多个线程，线程与线程之间需要通过互斥的手段进行同步，避免导致共享数据修改引起冲突。可以使用**互斥锁**，属于互斥量的一种。

### 4.5 线程通信和同步

线程间的通信方式包括**临界区、互斥量、信号量、条件变量、读写锁**

线程间的同步方式包括**互斥锁、信号量、条件变量、读写锁**

条件变量是用来等待线程而不是上锁的，条件变量通常和互斥锁一起使用。当条件满足的时候，线程通常解锁并等待该条件发生变化，一旦另一个线程修改了环境变量，就会通知相应的条件变量唤醒一个或者多个被这个条件变量阻塞的线程。

**互斥锁机制**：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

```cpp
acquire() {
    while (!available);
    /* busy wait */
    available = false;
}
release() {
    available = true;
}
```

**互斥锁和读写锁**：（1） 读写锁区分读者和写者，而互斥锁不区分（2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

**互斥锁**用于临界区持锁时间比较长的操作（临界区有IO操作、临界区代码复杂或者循环量大、临界区竞争非常激烈、单核处理器）；**自旋锁就**主要用在临界区持锁时间非常短且CPU资源不紧张的情况下

在C++中，锁 mutex 其实是对C语言 mutex 进行面向对象的封装，根据不同特定封装成不同的mutex类，并添加一些安全性检查之类的特性。

lock_guard 是严格基于作用域的RAII风格的 mutex 所有权包装器。每次使用 mutex 的时候都先调用lock()再调用unlock()，lock_guard在构造函数中加锁，在析构函数中解锁，在栈上申请的内存，超过作用域自动析构就解锁了。

RAII是“**资源获取即初始化**”，即在构造函数中申请分配资源，在析构函数中释放资源，**利用类来管理资源，将资源与类对象的生命周期绑定**，即在对象创建时获取对应的资源，在对象生命周期内控制对资源的访问，使之始终保持有效，最后在对象析构时，释放所获取的资源。std::shared_ptr和std::unique_ptr，std::lock_guard

```cpp
int value=0;
std::mutex mutex_;

void add(){
    mutex_.lock();
    ++value;
    mutex_.unlock();
}
// 上述函数等效于
void add(){
    std::lock_guard<std::mutex> guard(mutex_);
    ++value;
}
```

### 4.6 协程通信

（1）共享内存：和线程一样，协程也可以通过共享内存来进行通信，例如使用全局变量或者传递指向共享数据的指针等。

（2）Channel：Channel 是一种在协程间直接发送和接收值的方法，它提供了一种安全、方便的通信方式。一个 Channel 可以被看作是一个具有类型的管道，协程可以通过它发送或接收值。

（3）回调函数/闭包：另外一种常见的通信方式是通过回调函数或闭包。协程 A 可以将一个函数（可能带有上下文信息的闭包）传递给协程 B，协程 B 在适当的时候调用这个函数，从而实现和协程 A 的通信。

（4）消息队列/事件循环：这是另外一种常用的协程通信方式，特别是在 GUI 或网络编程中。协程将消息（事件）放入一个公共的队列，然后由事件循环处理并分发到对应的协程。

（5）条件变量/信号量：这是一种较低级的通信方式，通常用于同步或者互斥。

### 4.7 死锁

**锁的实现**：

1. 硬件支持：现代计算机硬件提供了一些原子操作（Atomic Operations），这些操作在单个指令周期内完成，不会被其它线程或进程中断。这些原子操作为实现锁提供了基础。其中，比较并交换（Compare-and-Swap, CAS）是一种常见的原子操作，可以检查某个内存位置的值是否等于预期值，如果是，则更新为新值。这种操作的原子性是通过硬件保证的。

2. 互斥锁（Mutex）：互斥锁主要依赖以上提到的原子操作来工作。在C++中，std::mutex就是一种常见的互斥锁。当你请求锁定一个mutex时，实际上执行的是一个原子操作，试图将该mutex置为"已锁定"状态。如果该操作成功，说明你获得了该mutex的所有权，可以安全地访问受保护的资源。如果失败，说明有其他线程拥有锁，你的线程就会被挂起，直到锁可用。

3. 调度和上下文切换：操作系统负责管理所有的线程，包括判断哪个线程应该运行，以及何时进行上下文切换。这部分也直接影响到锁的实现。例如，如果一个线程试图获取已经被其它线程占用的锁，操作系统会将该线程挂起，并将CPU转交给其它的线程。

4. 内存可见性与顺序：除了原子操作和线程调度外，锁还需要处理内存可见性和顺序问题。编译器和处理器可能会对指令进行重排以优化性能，但在并发环境下，这可能会导致问题。因此，锁需要使用内存屏障（Memory Barrier）或类似的机制来确保对内存的操作按照预期的顺序执行。

**原子性实现：**

1. 使用总线锁保证原子性。总线锁就是使用处理器提供的一个LOCK#信号,当一个处理器在总线上输出次信号时,其他处理器的请求将被阻塞住,那么该处理器可以独占共享内存

2. 使用缓存锁保证原子性。“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效。

**死锁** 指多个进程在执行过程中，因争夺资源而造成了互相等待。

死锁发生有**四个必要条件：互斥、请求保持、不可剥夺、循环等待**

资源一次性分配、可剥夺资源、资源有序分配

### 4.8 进程、线程的中断切换

**进程上下文切换**（1）保护被中断进程的处理器现场信息（2）修改被中断进程的进程控制块有关信息，如进程状态等（3）把被中断进程的进程控制块加入有关队列（4）选择下一个占有处理器运行的进程（5）根据被选中进程设置操作系统用到的地址转换和存储保护信息**切换页目录以使用新的地址空间切换内核栈和硬件上下文（包括分配的内存，数据段，堆栈段等）**（6）根据被选中进程恢复处理器现场

**线程上下文切换**（1）保护被中断线程的处理器现场信息（2）修改被中断线程的线程控制块有关信息，如线程状态等（3）把被中断线程的线程控制块加入有关队列（4）选择下一个占有处理器运行的线程（5）根据被选中线程设置操作系统用到的存储保护信息**切换内核栈和硬件上下文（切换堆栈，以及各寄存器）**（6）根据被选中线程恢复处理器现场

### 4.9 线程池

创建线程和销毁线程的花销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。**同时线程池也是为了提升系统效率。**

实现线程池有以下几个步骤：（1）设置一个生产者消费者队列，作为临界资源。（2）初始化n个线程，并让其运行起来，加锁去队列里取任务运行（3）当任务队列为空时，所有线程阻塞。（4）当生产者队列来了一个任务后，先对队列加锁，把任务挂到队列上，然后使用**条件变量**去通知阻塞中的一个线程来处理。

线程数量和哪些因素有关：CPU，IO、并行、并发。如果是CPU密集型应用，则线程池大小设置为：CPU数目+1 ；如果是IO密集型应用，则线程池大小设置为：2\*CPU数目+1；最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）\* CPU数目

## 5 操作系统内存管理

物理内存有四个层次，分别是 寄存器、高速缓存、主存、磁盘；**内存管理器**记录哪些内存是正在使用的，在进程需要时分配内存以及在进程完成时回收内存。

操作系统为每一个进程分配一个独立的地址空间，是虚拟内存。虚拟内存与物理内存存在映射关系，通过页表寻址完成虚拟地址和物理地址的转换。

进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap

**mmap是一种内存映射文件的方法**，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read, write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图：

![](/assets/img/mmap.png)

**使用场景**：对同一块区域频繁读写操作；可用于实现用户空间和内核空间的高效交互；可提供进程间共享内存及相互通信；可实现高效的大规模数据传输。

LRU算法用于缓存淘汰。思路是将缓存中最近最少使用的对象删除掉。利用**链表和hashmap，**当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。

```cpp
class LRUCache {
    list<pair<int, int>> cache;//创建双向链表
    unordered_map<int, list<pair<int, int>>::iterator> map;//创建哈希表
    int cap;
public:
    LRUCache(int capacity) {
        cap = capacity;
    }

    int get(int key) {
        if (map.count(key) > 0){
            auto temp = *map[key];
            cache.erase(map[key]);
            map.erase(key);
            cache.push_front(temp);
            map[key] = cache.begin();//映射头部
            return temp.second;
        }
        return -1;
    }

    void put(int key, int value) {
        if (map.count(key) > 0){
            cache.erase(map[key]);
            map.erase(key);
        }
        else if (cap == cache.size()){
            auto temp = cache.back();
            map.erase(temp.first);
            cache.pop_back();
        }
        cache.push_front(pair<int, int>(key, value));
        map[key] = cache.begin();//映射头部
    }
};
```

**为什么要用虚拟内存**：因为早期的内存分配方法存在以下问题：（1）进程地址空间不隔离。会导致数据被随意修改。（2）内存使用效率低，不能共享内存。（3）程序运行的地址不确定。操作系统随机为进程分配内存空间，所以程序运行的地址是不确定的。

**使用虚拟内存的好处**：（1）扩大地址空间。每个进程独占一个4G空间，虽然真实物理内存没那么多。（2）内存保护：防止不同进程对物理内存的争夺和践踏，可以对特定内存地址提供写保护，防止恶意篡改。（3）可以实现内存共享，方便进程通信。（4）可以避免内存碎片，虽然物理内存可能不连续，但映射到虚拟内存上可以连续。

**使用虚拟内存的缺点**：（1）虚拟内存需要额外构建数据结构，占用空间。（2）虚拟地址到物理地址的转换，增加了执行时间。（3）页面换入换出耗时。（4）一页如果只有一部分数据，浪费内存。

逻辑地址转线性地址：段起始地址+段内偏移地址=线性地址

线性地址转物理地址：（1）每一个32位的线性地址被划分为三部分：页目录索引（DIRECTORY，10位）、页表索引（TABLE，10位）、页内偏移（OFFSET，12位）（2）从**cr3**中取出进程的页目录地址（操作系统调用进程时，这个地址被装入寄存器中）

页表是虚拟内存的概念。**操作系统虚拟内存到物理内存的映射表，就被称为页表。**不可能每一个虚拟内存的 Byte 都对应到物理内存的地址。这张表将大得真正的物理地址也放不下，于是操作系统引入了页（Page）的概念。进行分页，这样可以减小虚拟内存页对应物理内存页的映射表大小。在系统启动时，操作系统将整个物理内存以 4K 为单位，划分为各个页。之后进行内存分配时，都以页为单位，那么虚拟内存页对应物理内存页的映射表就大大减小了，4G 内存，只需要 8M 的映射表即可，一些进程没有使用到的虚拟内存，也并不需要保存映射关系，而且Linux 还为大内存设计了多级页表，可以进一页减少了内存消耗。

**缺页异常**：malloc和mmap函数在分配内存时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个**缺页异常，引发缺页中断**。

缺页中断与一般中断一样，需要经历四个步骤：保护CPU现场、分析中断原因、转入缺页中断处理程序、恢复CPU现场，继续执行。

缺页中断与一般中断区别：

（1）在指令执行期间产生和处理缺页中断信号

（2）一条指令在执行期间，可能产生多次缺页中断

（3）缺页中断返回的是执行产生中断的一条指令，而一般中断返回的是执行下一条指令。

一个linux的线程大概占8M内存。linux的栈是通过缺页来分配内存的，不是所有栈地址空间都分配了内存。因此，8M是最大消耗，实际的内存消耗只会略大于实际需要的内存(内部损耗，每个在4k以内)。

**堆栈溢出**就是不顾堆栈中分配的局部数据块大小，向该数据块写入了过多的数据，导致数据越界。堆溢出：比如不断的new 一个对象；栈溢出：栈中将被依次压入参数，返回地址等，而方法递归比较深或进去死循环

32位是2的32次方，正好是4G，所以大于4G以上的内存就没办法表示；但是使用**PAE技术**就可以将地址扩展到了36位访问4GB以上的内存。

## 6 Linux系统态与用户态

**内核态与用户态**：**内核态**（系统态）与**用户态**是操作系统的两种运行级别。内核态拥有最高权限，可以访问所有系统指令；用户态则只能访问一部分指令。

**进入内核态**：共有三种方式：a、**系统调用**。b、**异常**。c、**设备中断**。其中，系统调用是主动的，另外两种是被动的。

在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。所以区分内核态与用户态主要是出于安全的考虑。

**零拷贝**：描述的是计算机操作系统当中，CPU不执行将数据从一个内存区域，拷贝到另外一个内存区域的任务。通过网络传输文件时，这样通常可以节省 CPU 周期和内存带宽。

**零拷贝的好处**：（1）节省了 CPU 周期，空出的 CPU 可以完成更多其他的任务（2）减少了内存区域之间数据拷贝，节省内存带宽（3）减少用户态和内核态之间数据拷贝，提升数据传输效率（4）应用零拷贝技术，减少用户态和内核态之间的上下文切换

![](/assets/img/0_copy.png)

1. 发起 sendfile() 系统调用，操作系统由用户态空间切换到内核态空间（第一次上下文切换）
2. 通过 DMA 引擎将数据从磁盘拷贝到内核态空间的输入的 socket 缓冲区中（第一次拷贝）
3. 将数据从内核空间拷贝到与之关联的 socket 缓冲区（第二次拷贝）
4. 将 socket 缓冲区的数据拷贝到协议引擎中（第三次拷贝）
5. sendfile() 系统调用结束，操作系统由用户态空间切换到内核态空间（第二次上下文切换）

根据以上过程，一共有 2 次的上下文切换，3 次的 I/O 拷贝。我们看到从用户空间到内核空间并没有出现数据拷贝，**从操作系统角度来看，这个就是零拷贝**。内核空间出现了复制的原因: 通常的硬件在通过DMA访问时期望的是连续的内存空间。

**mmap 数据零拷贝原理，如果需要对数据做操作，Linux 提供了mmap 零拷贝来实现。**

磁盘里的文件传到网络，要拷贝几次？零拷贝技术的话两次，一次为磁盘拷贝到内核缓冲区，另一次为内核缓冲区拷贝到网卡缓冲区。

## 7 IO模型

**IO模型的类型：**

（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

（2）非阻塞IO：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

（3）信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO信号，然后处理IO事件。

（4）IO多路复用：Linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检查。知道有数据可读或可写时，才真正调用IO操作函数。

（5）异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。

前四种模型都属于**同步模式**，因为其中真正的IO操作(函数)都将会阻塞进程，只有**异步IO模型**真正实现了IO操作的异步性。

**同步与异步的区别**

**阻塞与非阻塞的区别：**调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作；非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

**BIO（Blocking I/O）**：**阻塞IO；**

- 服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求（必须等上一个请求处recv或send完），无法处理并发
- 服务器端采用多线程，当accept一个请求后，开启线程进行recv，可以完成并发处理，但随着请求数增加需要增加系统线程

**NIO（NONBLOCK IO）**

- 服务器端当accept一个请求后，加入fds集合，每次轮询一遍fds集合recv(非阻塞)数据，没有数据则立即返回错误，每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu

**select，poll，epoll**都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

> **select和poll工作流程：**
> 1. 当用户调用 select() 时，select() 会在用户进程中将应用程序传给它的文件描述符集合复制到内核空间。
> 2. 然后，select() 将控制权交还给用户进程。用户进程可以继续执行其他操作，直到内核准备好数据为止。
> 3. 当 socket 上有可用数据时，也就是说数据已经从网络上读取并缓存在 socket 内部的缓冲区中时，或者这些 socket 已经关闭，或者 socket 上发生了错误等情况，此时 select() 在内核中返回。
> 4. 随后，用户进程再次调用 select()，但现在调用立即返回。用户进程必须再次把全部文件描述符从用户空间复制到内核空间。
> 5. 这时，用户进程便得知哪些 socket 准备好了数据，并进行相应的读写操作。

**select和poll**进程通过告诉多路复用器（内核）（也就是select函数和poll函数）所有的socket号（将应用程序传给它的文件描述符集合复制到内核空间），多路复用器再去获取每一个socket的状态，当程序获取到某个socket号有事件发生了，则去该socket号上进行处理对应的事件，read事件或者是recived事件。（补充select函数与poll函数的区别是，前者底层是数组，所以有最大连接数的限制，后者是链表，无最大连接数的限制）

**缺点**：①同样与NIO相同，需要遍历所有socket，O（N）复杂度。②重复传递数据。因为内核是无状态的，每次都要根据进程不断重复从用户态向内核态传递所有的socket号去遍历每一个socket，获取它们的状态。浪费资源与效率，可以使用一个记事本记录每个socket的监听事件。

**epoll底层流程**：

- 创建epoll对象：创建一个eventpoll对象以维护就绪列表 
- 维护监视列表：对socket添加或者删除监听，内核将eventpoll添加到socket的等待队列中。
- 接受数据：当socket接受到数据之后，中断程序会给eventpoll的就序列表添加socket引用
- 阻塞和唤醒进程：循环调用epoll_wait() 函数进行监听，返回已经就绪事件序列的长度（返回0则说明无状态，大于0则说明有n个事件已就绪）。

select：调用开销大（需要复制集合）；集合大小有限制；需要遍历整个集合找到就绪的描述符

poll：采用数组的方式存储文件描述符，没有最大存储数量的限制，其他方面和 select 没有区别

epoll：调用开销小（不需要复制）；集合大小无限制；采用回调机制，不需要遍历整个集合

select、poll 都是在用户态维护文件描述符集合，因此每次需要将完整集合传给内核；epoll 由操作系统在内核中维护文件描述符集合，因此只需要在创建的时候传入文件描述符。此外 select 只支持水平触发，epoll 支持边缘触发。

当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多。当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能可能低于其它两者。

**epoll水平触发与边缘触发的区别：**LT模式（水平触发）下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作；而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。

1. **Reactor模式**：Reactor模式应用于同步I/O的场景。Reactor中读操作的具体步骤如下：读取操作：（1）应用程序注册读就需事件和相关联的事件处理器（2）事件分离器等待事件的发生（3）当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器（4）事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理
2. **Proactor模式**：Proactor模式应用于异步I/O的场景。Proactor中读操作的具体步骤如下：（1）应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。（2）事件分离器等待读取操作完成事件（3）在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。（4）事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
3. **区别**：从上面可以看出，Reactor中需要**应用程序自己读取或者写入数据**，而Proactor模式中，应用程序不需要用户再自己接收数据，直接使用就可以了，操作系统会将数据从**内核拷贝到用户区**。

## 8 socket网络编程

![image.png](/assets/img/socket.png)

**服务器端函数**：

（1）socket创建一个套接字

（2）bind绑定ip和port

（3）listen使套接字变为可以被动链接

（4）accept等待客户端的链接

（5）write/read接收发送数据

（6）close关闭连接

**客户端函数**：

（1）创建一个socket，用函数socket()

（2）bind绑定ip和port

（3）连接服务器，用函数connect()

（4）收发数据，用函数send()和recv()，或read()和write()

（5）close关闭连接

## 9 软中断和硬中断

## 10 系统级优化

系统高性能：

1. 硬件选择和配置：选择适合应用需求的硬件极其重要。例如，对于需要大量计算的任务，我们可能需要一个拥有更多CPU核心的处理器；对于I/O密集型应用，我们可能需要高速的SSD硬盘或高速网络。

2. 负载均衡：如果你的系统接收到大量请求，可以使用负载均衡器如Nginx、HAProxy等，将请求分散到多台服务器，以减轻单个服务器的压力。

3. 并发和多线程：并行化你的工作流程，利用多核处理器来提高性能。你可以使用多线程，或者采用异步编程模型。

4. 内存管理：了解并优化你的系统的内存使用情况。使用缓存来避免昂贵的磁盘I/O操作，同时注意防止出现内存泄漏。

5. 数据库优化：选择合适的数据库类型（关系型或非关系型），合理设计数据库结构，以及使用索引来加快查询速度。对于数据量特别大的场景，可以考虑使用数据分片（sharding）。

6. 网络优化：减少网络延迟，如优化TCP设置，使用CDN(Content Delivery Network)，压缩数据等。

系统高并发：

1. 多进程：每个进程都有自己独立的内存空间和环境变量，进程之间互不影响。但由于创建进程的开销比较大，因此适合计算密集型的任务。

2. 多线程：一个进程中可以包含多个线程，同一进程内的多个线程共享该进程的地址空间和资源，如文件描述符等。但同时也要注意线程间的数据同步和互斥问题。多线程适用于I/O密集型任务。

3. 事件驱动模型（异步IO）：在这种设计模式下，程序会在I/O操作开始时提交一个请求，并继续执行其他任务。当I/O操作完成时，程序会收到一个事件并回来处理这个事件。这种模型可以消除等待I/O的时间，非常适合I/O密集型的应用。

4. 预先创建进程/线程池：为避免频繁地创建和销毁进程/线程所带来的开销，可以预先创建一定数量的进程/线程，形成一个池。当有新的请求到来时，可以直接从池中取一个进程/线程来处理。

5. 负载均衡：通过负载均衡，可以将请求分发给多个进程/服务器，从而达到高并发。负载均衡可以通过轮询、最少连接、IP哈希等策略来分配任务。

6. 使用非阻塞I/O和I/O多路复用技术：如select, poll, epoll等，可以使单个进程同时处理多个I/O请求。

7. 利用缓存和队列：缓存可以减少数据库访问，队列则可以缓冲突发流量，进一步提高并发性能。

8. 优化代码：避免在关键路径上进行锁操作，减少系统调用等，都能有效提高并发性能。