---
layout: post
title: Mysql
date: 2023-10-29 19:44 +0800
categories: [mysql]
tags: [mysql]
toc:  true
---

## 1 存储引擎

存储引擎是实现存储数据、为存储的数据建立索引和更新以及查询数据等技术的方法。

```sql
-- 查看支持的存储引擎
SHOW ENGINES

-- 查看默认存储引擎
show variables like 'default_storage_engine';

-- 查看数据库表的存储引擎
show table status like "tablename";
show table status from database where name="tablename";

-- 设置存储引擎
create table tablename (...) ENGINE = INNODB/MYISAM;
alter table tablename ENGINE = INNODB/MYISAM;

-- 修改默认存储引擎
SET default_storage_engine = INNODB/MYISAM;
```

INNODB和MYISAM的区别

|  | MYISAM | INNODB |
| --- | --- | --- |
| 主键 |必须有，用于实现聚簇索引| 可以没有|
| 外键 | 不支持 | 支持 |
| 事务 | 不支持 | 支持 |
| 行表锁 | 表锁，操作一条记录也会锁住整个表，不适合高并发操作 | 行锁，操作时只锁其中一行，适合高并发 |
| 缓存 | 只缓存索引 | 不仅要缓存索引还要缓存真实数据，对内存要求较高 |
| 表空间 | 小 | 大 |
| 关注点 | 性能 | 事务 |
| 索引 | 非聚簇索引，数据文件和索引分离，索引保存的时数据文件指针 | 聚簇索引，数据放在主键索引的叶子节点上，辅助索引需要两次查询 |
|hash索引|支持|不支持|
|记录存储顺序|按照主键大小有序插入|按记录插入顺序保存|

INNODB不保存表的具体行数，执行`select count(*) from tablename;`需要全表扫描；但是MYISAM使用一个变量保存了该值，执行上述语句时直接读出即可。
一张表里面有自增的ID主键，当insert了17条记录后，删除第15、16、17条记录，在把Mysql重启再次insert一条记录，这条记录的ID时多少？
**MYISAM引擎时是18，INNODB引擎时是15。**

**InnoDB四大特性**

插入缓存（insert buffer）
InnoDB 存储引擎设计了 Insert Buffer ，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池（Buffer pool）中，若在，则直接插入；若不在，则先放入到一个 Insert Buffer 对象中，然后再以一定的频率和情况进行 Insert Buffer 和辅助索引页子节点的 merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能。

插入缓冲的使用需要满足以下两个条件：
- 索引是辅助索引；
- 索引不是唯一的；

二次写（double write）
doublewrite 由两部分组成，一部分为内存中的 doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间中连续的128个页，即2个区(extent)，大小也是2M。为了解决 partial page write（部分页定入） 问题，当 MySQL 将脏数据刷新到磁盘的时候，会进行以下操作：
先将脏数据复制到内存中的 doublewrite buffer；
之后通过 doublewrite buffer 再分2次，每次1MB写入到共享表空间的磁盘上（顺序写，性能很高）；
完成第二步之后，马上调用 fsync 函数，将doublewrite buffer中的脏页数据写入实际的各个表空间文件（离散写）。

自适应哈希索引（adaptive hash index）
InnoDB 会监控对表上索引的查找，如果观察到某些索引被频繁访问，索引成为热数据，建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的。自适应哈希索引通过缓冲池的 B+ 树构造而来，因此建立的速度很快。而且不需要将整个表都建哈希索引，InnoDB 会自动根据访问的频率和模式来为某些页建立哈希索引。

预读（read ahead）
线性预读（Linear read-ahead）：线性预读方式有一个很重要的变量 innodb_read_ahead_threshold，可以控制 Innodb 执行预读操作的触发阈值。如果一个 extent 中的被顺序读取的 page 超过或者等于该参数变量时，Innodb将会异步的将下一个 extent 读取到 buffer pool中，innodb_read_ahead_threshold 可以设置为0-64（一个 extend 上限就是64页）的任何值，默认值为56，值越高，访问模式检查越严格。
随机预读（Random read-ahead）: 随机预读方式则是表示当同一个 extent 中的一些 page 在 buffer pool 中发现时，Innodb 会将该 extent 中的剩余 page 一并读到 buffer pool中，由于随机预读方式给 Innodb code 带来了一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃。要启用此功能，请将配置变量设置 innodb_random_read_ahead 为ON。


## 2 数据类型

整数类型：TINYINT、SMALLINT、MEDIUMINT、INT(4 B)、BIGINT、FLOAT、DOUBLE
日期类型：DATE、TIME、YEAR、DATETIME、TIMESTAM
字符串类型：CHAR(255 B 固定大小)、VARCHAR(65535 B)、BOLB(65535 B)、TEXT(65535 B)

CHAR和VARCHAR区别：
相同点：1）char(n)和varchar(n)都代表最大可容纳字符的个数为n；2）超过最大长度n的部分将会被截断
不同点：1）char无论实际字符是多少都会占用n个字符的空间，而varchar只会占用实际字符空间加1（0<=length<255）或者加2（length>255），多出的字节用来保存长度；2）能存储的最大长度不同；3）char在存储时会截断尾部的空格。

datetime 和 timestamp 的区别
datetime能保存大范围的值，从1001~9999年，精度为秒。把日期和时间封装到了一个整数中，与时区无关，使用8字节存储空间。
timestamp**只使用4字节的存储空间**，范围比datetime小，只能表示1970~2038年，并且依赖于时区。

varchar(50)中50的含义
最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。

int(20)中20的含义
是指显示字符的长度。20表示最大显示宽度为20，但仍占4字节存储，存储范围不变；不影响内部存储，只是影响带 zerofill 定义的 int 时，前面补多少个 0，易于报表展示。

float和double的区别
FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。
DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。

drop、delete与truncate的区别
delete和truncate只删除表的数据不删除表的结构；
delete语句是DML操作，事务提交后才会生效；若有相应的触发器(trigger)，执行时会被触发；
truncate和drop是DDL操作，操作立即生效，不能回滚，不触发触发器（trigger）
SQL 执行速度： drop > truncate > delete

## 3 索引

索引是一个单独的、存储在磁盘上的数据库结构，使用索引可以快速找出在某个或多个列中有一特定值的行，所有MySQL列类型都可以被索引，对相关列使用索引是提高查询操作速度的最佳途径。
MySQL中索引的存储类型有两种，即BTREE和HASH，具体和表的存储引擎相关。MyISAM和InnoDB存储引擎只支持BTREE索引；MEMORY存储引擎可以支持HASH和BTREE索引。

```sql
-- 在创建表的时候创建索引
-- 如果是CHAR、VARCHAR类型则length可以小于实际长度，如果是BOLB和TEXT类型则length必须指定
CREATETABLE table_name [col_name data_type]
[UNIQUE|FULLTEXT|SPATIAL] [INDEX|KEY] [index_name] (col_name [length]) 
[ASC|DESC]
-- 例如
CREATE TABLE t1 (
    id INT NOT NULL,
    name CHAR(30) NOT NULL,
    UNIQUE INDEX UniqIdx(id)
);
```

UNIQUE、FULLTEXT和SPATIAL为可选参数，分别表示唯一索引、全文索引和空间索引；INDEX与KEY为同义词，两者作用相同，用来指定创建索引

```sql
-- 在已存在的表上创建索引
ALTER TABLE table_name ADD 
[UNIQUE|FULLTEXT|SPATIAL] [INDEX|KEY] [index_name] (col_name[length],...) 
[ASC|DESC];

CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name 
ON table_name (col_name [length],...) [ASC|DESC];

-- 删除索引
DROP INDEX [indexname] on tablename;
-- 查看
show INDEX from tablename\G;
```

只要创建了索引，就一定会走索引？：
不一定。在使用组合索引的时候，如果没有遵从“最左前缀”的原则进行搜索，则索引是不起作用的。假设在id、name、age字段上已经成功建立了一个名为MultiIdx的组合索引，（name,age）组合则不能使用该索引查询

判断数据库的索引有没有生效？
```sql
EXPLAIN SELECT * FROM book WHERE year_publication=1990;
-- EXPLAIN语句将为我们输出详细的SQL执行信息
-- possible_keys行给出了MySQL在搜索数据记录时可选用的各个索引。
-- key行是MySQL实际选用的索引
```

评估一个索引创建的是否合理：

1. 避免对经常更新的表进行过多的索引，并且索引中的列要尽可能少。应该经常用于查询的字段创建索引，但要避免添加不必要的字段。
2. 数据量小的表最好不要使用索引，查询花费的时间可能比遍历索引的时间还要短。
3. 在条件表达式中经常用到的不同值较多的列上建立索引，在不同值很少的列上不要建立索引。比如在学生表的“性别”字段上只有“男”与“女”两个不同值，因此就无须建立索引，如果建立索引不但不会提高查询效率，反而会严重降低数据更新速度。
4. 当唯一性是某种数据本身的特征时，指定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度。
5. 在频繁进行排序或分组（即进行group by或order by操作）的列上建立索引，如果待排序的列有多个，可以在这些列上建立组合索引。

索引并非越多越好，一个表中如有大量的索引，不仅占用磁盘空间，还会影响INSERT、DELETE、UPDATE等语句的性能，因为在表中的数据更改时，索引也会进行调整和更新。

避免索引失效：

1. 使用组合索引时，需要遵循“最左前缀”原则
2. 不在索引列上做任何操作，例如计算、函数、类型转换，会导致索引失效而转向全表扫描；`select * from A where A.id + 1 = 10003;`
3. 使用了左模糊`col_name LIKE '%ABC'`，避免左模糊使用`col_name LIKE 'ABC%'`
```sql
// 翻转函数+like前模糊查询+建立翻转函数索引=走翻转函数索引
SELECT object_name from t1 WHERE object_name LIKE '%ABC';

CREATE INDEX idx_t1_objectname2 ON t1(reverse(object_name));
SELECT object_name FROM t1 WHERE REVERSE(object_name) LIKE REVERSE('%ABC');
```
4. 使用or查询的部分字段没有索引`select * from employees where first_name ='Georgi' or last_name ='Georgi';`
5. 字符串条件未使用 ' '引起来
6. 索引字段建议添加 NOT NULL约束
7. 尽量使用覆盖索引（之访问索引列的查询），减少 select * 覆盖索引能减少回表次数
8. MySQL在使用不等于（!=或者<>）的时候无法使用索引会导致全表扫描

索引的优点主要有以下几条：

1. 通过创建唯一索引，可以保证数据库表中每一行数据的唯一性。
2. 可以大大加快数据的查询速度，这也是创建索引的主要原因。
3. 在实现数据的参考完整性方面，可以加速表和表之间的连接。
4. 在使用分组和排序子句进行数据查询时，也可以显著减少查询中分组和排序的时间。

增加索引也有许多不利的方面，主要表现在如下几个方面：

1. 索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸。
2. 当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。

MySQL的索引可以分为以下几类：

1. 普通索引和唯一索引，普通索引是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值。唯一索引要求索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。主键索引是一种特殊的唯一索引，不允许有空值。
2. 单列索引和组合索引，单列索引即一个索引只包含单个列，一个表可以有多个单列索引。组合索引是指在表的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用。使用组合索引时遵循最左前缀集合。
3. 全文索引，全文索引类型为FULLTEXT，在定义索引的列上支持值的全文查找，允许在这些索引列中插入重复值和空值。全文索引可以在CHAR、VARCHAR或者TEXT类型的列上创建。MySQL中只有MyISAM存储引擎支持全文索引。
4. 空间索引，空间索引是对空间数据类型的字段建立的索引，MySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。MySQL使用SPATIAL关键字进行扩展，使得能够用创建正规索引类似的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MyISAM的表中创建。

B-Tree特征（m阶）：

- 根结点至少有两个子女;
- 每个非根节点所包含的关键字个数 j 满足：⌈m/2⌉ - 1 <= j <= m - 1
- 有k个关键字(关键字按递增次序排列)的非叶结点恰好有k+1个孩子
- 所有的叶子结点都位于同一层，且不包含其他关键字信息

B+Tree特征（不同）：

- B-树在非叶子节点也存储数据信息
- 非叶子节点只存储键值信息
- B+树相邻的叶子节点之间是通过链表指针连起来的
- 数据记录都放在叶子节点

B+Tree和B-Tree的优势：

- B-树只适合随机检索，B+树同时支持随机检索和顺序检索；B-树遍历元素效率低下，B+树的叶子节点使用指针顺序连接在一起
- B+树I/O次数更少，磁盘读写代价低
- B+树的查询效率稳定
- B+树增删效率更高

索引实现原理：MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。
B+树索引在数据库中的一个特点就是**高扇出性**，在InnoDB存储引擎中，每个页的大小为16KB。B+树的高度一般都在2～4层，这意味着查找某一键值最多只需要2到4次IO操作
![image.png](/assets/img/mylsam_engine.png)
InnoDB的数据文件本身就是索引文件。在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录（聚集索引）。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。InnoDB的辅助索引data域存储相应记录主键的值而不是地址
![image.png](/assets/img/innodb_engine.png)

**回表查询**
在InnoDB中，对于主键索引，只需要跑一遍主键索引的查询就能获取叶子节点的数据。
对于普通索引，叶子节点存储的是 key + 主键值，所以还需要跑一遍主键索引的查询才能找到数据行，这就是回表查询，先定位主键值，再定位数据行。

问题：普通索引一定会出现回表查询吗？
若查询SQL所要求的字段全部命中索引，那就不用进行回表查询。比如有一个user表，主键为id，name是个普通索引，执行SQL：select id,name from user where name='aitao'时，通过name的索引就可以获取到id和name数据，所以无需回表查询数据行。

索引重构过程：
什么时候需要重建索引，表上频繁发生update,delete操作；表上发生了alter table ..move操作（move操作导致了rowid变化）。

判断索引是否应该重建：
```sql
-- 看索引是否倾斜的严重，是否浪费了空间，对索引进行结构分析：
analyze index index_name validate structure;
-- 在相同的session中查询index_stats表
select height,DEL_LF_ROWS/LF_ROWS from index_stats;
-- 当查询的height>=4（索引的深度，即从根到叶节点的高度）或DEL_LF_ROWS/LF_ROWS>0.2的情况下，就应该考虑重建该索引
```

重建索引：
```sql
drop index index_name;
create index index_name on table_name (index_column);
-- 直接重建索引
alter index indexname rebuild;
alter index indexname rebuild online;
```

rebuild是一种使用现有索引项来重建新索引的方法。如果重建索引时有其他用户在对这个表操作，尽量使用带online参数来最大限度的减少索引重建时将会出现的任何加锁问题。由于新旧索引在建立时同时存在，使用这种重建方法需要有额外的磁盘空间可供临时使用，当索引建完后把老索引删除，如果没有成功，也不会影响原来的索引。利用这种办法可以用来将一个索引移到新的表空间。

rebuild重建索引的过程：

1. Rebuild以index fast full scan或table full scan方式（采用那种方式取决于cost）读取原索引中的数据来构建一个新的索引，重建过程中有排序操作，rebuild online执行表扫描获取数据，重建过程中有排序的操作；
2. Rebuild会阻塞DML（增删改查）操作，rebuild online不会阻塞DML操作；
3. rebuild online时系统会产生一个SYS_JOURNAL_xxx的IOT类型的系统临时日志表，所有rebuild online时索引的变化都记录在这个表中，当新的索引创建完成后，把这个表的记录维护到新的索引中去，然后drop掉旧的索引，rebuild online就完成了。

联合索引的存储结构：
联合索引还是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2，参考下图。只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，所以使用联合索引时遵循最左前缀集合。
**最左前缀原则**：MySQL会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配。比如`a=1 and b=2 and c>3 and d=4`，若建立(a,b,c,d)顺序的索引，d是用不到索引的。若建立(a,b,d,c)顺序的索引，则可以使用到，a,b,d的顺序根据业务需要可以任意调整。
>=和in可以乱序，比如`a = 1 and b = 2 and c = 3 `建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

![image.png](/assets/img/mysql_mutil_index.png)

MySQL的Hash索引和B树索引：

- hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。
- hash索引不支持使用索引进行排序，原理同上。
- hash索引不支持模糊查询以及多列索引的最左前缀匹配，原理也是因为hash函数的不可预测。
- hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。
- hash索引虽然在等值查询上较快，但是不稳定，性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。

```sql
select  au_id,au_lname,au_fname
from   authors
where  state  IN ('CA','KS','MI','IN')
```

select in语句中如何使用索引：索引是否起作用，主要取决于字段类型，如果字段类型为字符串，需要给in查询中的数值与字符串值都需要添加引号，索引才能起作用。如果字段类型为int，则in查询中的值不需要添加引号，索引也会起作用。

## 4 MYSQL查询

MySQL执行一条查询语句的内部执行过程：

- 客户端（运行程序）先通过连接器连接到MySQL服务器
- 连接器通过数据库权限身份验证后，先查询数据库缓存是否存在（之前执行过相同条件的SQL查询），如果有会直接返回缓存中的数据。如果没有则会进入分析器
- 进入分析器后会对查询语句进行语法的分析，判断该查询语句SQL是否存在语法错误，如果存在查询语法错误，会直接返回给客户端错误，如果正确会进入优化器
- 优化器会对查询语句进行优化处理：如：如果一条语句用到了多个索引会判断哪个索引性能更好
- 最终会进入执行器，开始执行查询语句直到查询出满足条件的所有数据，然后进行返回

## 5 事务

在事务中的操作，要么都执行修改，要么都不执行

- A（atomicity），原子性。原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，整个事务的执行才算成功。事务中任何一个SQL语句执行失败，数据库状态应该退回到执行事务前的状态。
- C（consistency），一致性。一致性指事务将数据库从一种状态转变为另一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。
- I（isolation），隔离性。事务的隔离性要求每个读写事务的对象与其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，这通常使用锁来实现。
- D（durability） ，持久性。事务一旦提交，其结果就是永久性的，即使发生宕机等故障，数据库也能将数据恢复。持久性保证的是事务系统的高可靠性，而不是高可用性。

事务可以分为以下几种类型：

- 扁平事务：是事务类型中最简单的一种，而在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束。处于之间的操作是原子的，要么都执行，要么都回滚。
- 带有保存点的扁平事务：除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（savepoint）用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态。
- 链事务：可视为保存点模式的一个变种。链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的。
- 嵌套事务：是一个层次结构框架。有一个顶层事务（top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换。
- 分布式事务：通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。对于分布式事务，同样需要满足ACID特性，要么都发生，要么都失效。

对于嵌套事务，MySQL数据库并不是原生的，因此对于有并行事务需求的用户来说MySQL就无能为力了，但是用户可以通过带有保存点的事务来模拟串行的嵌套事务。

**原子性实现原理：** 实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚靠的是undo log，当事务对数据库进行修改时，InnoDB会生成对应的undo log。如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。
undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作。对于insert，回滚时会执行delete。对于delete，回滚时会执行insert。对于update，回滚时则会执行相反的update，把数据改回去。

**持久性实现原理：** InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲。当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool。当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。
Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。
于是，redo log被引入来解决这个问题。当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。

既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：

- 刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。
- 刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入。而redo log中只包含真正需要写入的部分，无效IO大大减少。

**隔离性实现原理：** 隔离性追求的是并发情形下事务之间互不干扰。简单起见，我们主要考虑最简单的读操作和写操作(加锁读等特殊读操作会特殊说明)，那么隔离性的探讨，主要可以分为两个方面。
第一方面，(一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性。
隔离性要求同一时刻只能有一个事务对数据进行写操作，InnoDB通过锁机制来保证这一点。锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁。获得锁之后，事务便可以修改数据。该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。
按照粒度，锁可以分为表锁、行锁以及其他位于二者之间的锁。表锁在操作数据时会锁定整张表，并发性能较差。行锁则只锁定需要操作的数据，并发性能好。MySQL中不同的存储引擎支持的锁是不一样的，例如MyIsam只支持表锁，而InnoDB同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁。
第二方面，(一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性。
InnoDB默认的隔离级别是RR（REPEATABLE READ），RR解决脏读、不可重复读、幻读等问题，使用的是MVCC。MVCC全称Multi-Version Concurrency Control，即多版本的并发控制协议。它最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. 隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等。
2. 基于undo log的版本链：每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。
3. ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本。但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。

**一致性实现原理（AID特性的undlog、redolog、binlog日志保证数据一致性）：** 实现一致性的措施包括

- 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证。
- 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等。
- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。

**快照读**：生成一个事务快照（ReadView），之后都从这个快照获取数据。普通 select 语句就是快照读。

**当前读**：读取数据的最新版本。常见的 update/insert/delete、还有 select … for update、select … lock in share mode 都是当前读。

SQL 标准定义了四种隔离级别，这四种隔离级别分别是：读未提交（READ UNCOMMITTED）；读提交 （READ COMMITTED）；可重复读 （REPEATABLE READ）；串行化 （SERIALIZABLE）。

并发情况下，读操作可能存在的三类问题：

1. 脏读：当前事务(A)中可以读到其他事务(B)未提交的数据（脏数据），这种现象是脏读。
2. 不可重复读：在事务A中先后两次读取同一个数据，两次读取的结果不一样，这种现象称为不可重复读。
3. 幻读：在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。

| **隔离级别** | **脏读** | **不可重复读** | **幻读** |
| --- | --- | --- | --- |
| READ UNCOMMITTED | 可能 | 可能 | 可能 |
| READ COMMITTED | 不可能 | 可能 | 可能 |
| REPEATABLE READ | 不可能 | 不可能 | 可能 |
| SERIALIZABLE | 不可能 | 不可能 | 不可能 |

上述4种隔离级别MySQL都支持，并且InnoDB存储引擎默认的支持隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock的锁算法，因此避免了幻读的产生。所以，InnoDB存储引擎在默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。
读未提交（READ UNCOMMITTED）：不加锁
串行化 （SERIALIZABLE）：读的时候加共享锁，其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。
读提交 （READ COMMITTED）和可重复读 （REPEATABLE READ）：MySQL 采用了 MVVC (多版本并发控制) 的方式

我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为 row trx_id，而这个字段就是使其产生的事务的 id，事务 ID 记为 transaction id，它在事务开始的时候向事务系统申请，按时间先后顺序递增。
![image.png](/assets/img/transaction_process.png)
可重复读是在事务开始的时候生成一个当前**事务全局性的快照**，而读提交则是每次执行语句的时候都重新生成一次快照。对于一个快照来说，它能够读到那些版本数据，要遵循以下规则：

1. 当前事务内的更新，可以读到；
2. 版本未提交，不能读到；
3. 版本已提交，但是却在快照创建后提交的，不能读到；
4. 版本已提交，且是在快照创建前提交的，可以读到。

**两者主要的区别就是在快照的创建上，可重复读仅在事务开始是创建一次，而读提交每次执行语句的时候都要重新创建一次。**
MySQL 已经在可重复读隔离级别下解决了幻读的问题，用的是间隙锁。MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题，这个锁叫做 Next-Key锁。假设现在表中有两条记录，并且 age 字段已经添加了索引，两条记录 age 的值分别为 10 和 30。在数据库中会为索引维护一套B+树，用来快速定位行记录
![image.png](/assets/img/next_lock.png)
在事务A提交之前，事务B的插入操作只能等待，这就是间隙锁起得作用。由于条件 where age = 10 ，数据库不仅在 age =10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁

在MySQL默认的配置下，事务都是自动提交和回滚的。当显示地开启一个事务时，可以使用ROLLBACK语句进行回滚。该语句有两种用法：

- ROLLBACK：要使用这个语句的最简形式，只需发出ROLLBACK。同样地，也可以写为ROLLBACK WORK，但是二者几乎是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。
- ROLLBACK TO [SAVEPOINT] identifier ：这个语句与SAVEPOINT命令一起使用。可以把事务回滚到标记点，而不回滚在此标记点之前的任何工作。

## 6 锁

InnoDB存储引擎实现了如下两种标准的行级锁：

- 共享锁（S Lock），允许事务读一行数据。
- 排他锁（X Lock），允许事务删除或更新一行数据。

锁的粒度：行锁和表锁，为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁。如果我们给某一行的数据添加了锁，数据库会自动给更大的一级空间添加上意向锁（比如数据页或表），表示该数据页或数据表已经存在锁了。

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁。

![image.png](/assets/img/mysql_lock_table.png)


锁的算法有Record Lock：单个行记录上的锁；Gap Lock：间隙锁，锁定一个范围，但不包含记录本身；Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。
Innodb 加锁 [InnoDB的三种行锁(提供具体sql执行案例分析)](https://blog.csdn.net/LT11hka/article/details/131392416)

乐观锁和悲观锁：乐观锁可以采用CAS（Compare And Swap）的方式，乐观的认为产生锁冲突的概率较小。适用于锁冲突概率比较小的场景。时间戳机制：通过比较时间戳判断数据是否被修改。
![](/assets/img/compare_swap_lock.png)
悲观锁：依靠数据库提供的锁机制来实现。
SELECT … FOR UPDATE是MySQL中的悲观锁，执行过程会将所有扫描的行都锁上，因此在MySQL中用悲观锁必须使用索引，而不是全表扫描，否则会将整张表锁住。

关于死锁：解决死锁问题最简单的一种方法是超时；当前数据库还都普遍采用wait-for graph（等待图，InnoDB存储引擎使用）的方式来进行死锁检测。wait-for graph要求数据库保存以下两种信息：（1）锁的信息链表；（2）事务等待链表；
通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁。这是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量**最少行排他锁**的事务。

## 7 MYSQL优化

**limit优化：**
数据库分页：为了返回第一行或前几行，可使用LIMIT子句，以实x现分页查询

```sql
SELECT prod_name FROM products LIMIT 5;
-- 在所有的查询结果中，从第5行开始，返回5行记录
SELECT prod_name FROM products LIMIT 4,5;
```

优化LIMIT分页，比如LIMIT 10000,20；①优化此类分页查询的一个最简单的办法就是尽可能地使用**索引覆盖扫描**，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列。

```sql
SELECT film_id,description FROM sakila.film ORDER BY title LIMIT 50,5;
-- 优化，INNER JOIN内连接，USING指定连接的列为file_id，AS重命名
SELECT film.film_id,film.description 
FROM sakila.film
INNER JOIN (
    SELECT film_id FROM sakila.film ORDER BY title LIMIT 50,5
) AS lim USING(film_id);
```

索引覆盖扫描分为子查询优化和延迟关联（inner join）。
②如果可以使用书签记录上次取数的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET

```sql
-- 假设上面的查询返回的是主键1000000之前的记录
select * from t5 where id>=1000000 limit 10;
```

**内连接：**
内连接通过INNER JOIN来实现，它将返回两张表中满足连接条件的数据，不满足条件的数据不会查询出来。
外连接通过OUTER JOIN来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。外连接有两种形式：左外连接（LEFT OUTER JOIN）、右外连接（RIGHT OUTER JOIN）。

- 左外连接：可以简称为左连接（LEFT JOIN），它会返回左表中的所有记录和右表中满足连接条件的记录。
- 右外连接：可以简称为右连接（RIGHT JOIN），它会返回右表中的所有记录和左表中满足连接条件的记录。

还有一种常见的连接方式：等值连接<=>内连接
从表的关系上来说，比较常见的关联关系有：一对多关联、多对多关联、自关联。

- 一对多关联：这种关联形式最为常见，一般是两张表具有主从关系，并且以主表的主键关联从表的外键来实现这种关联关系。另外，以从表的角度来看，它们是具有多对一关系的，所以不再赘述多对一关联了。
- 多对多关联：这种关联关系比较复杂，如果两张表具有多对多的关系，那么它们之间需要有一张中间表来作为衔接，以实现这种关联关系。这个中间表要设计两列，分别存储那两张表的主键。因此，这两张表中的任何一方，都与中间表形成了一对多关系，从而在这个中间表上建立起了多对多关系。
- 自关联：自关联就是一张表自己与自己相关联，为了避免表名的冲突，需要在关联时通过别名将它们当做两张表来看待。一般在表中数据具有层级（树状）时，可以采用自关联一次性查询出多层级的数据。

**SQL行转成列：**
SQL聚合函数：COUNT()、AVG()、SUM()、MAX()、MIN()
- count(主键id)：使用这个方式，InnoDB 会遍历整个表，把所有的 id 值都传给 sever 层。sever 层拿到 id 后，可以直接按行累加（id 不能为空）。
- count(1)：InnoDB 会遍历整个表，但是不取值。sever 对返回的每一行，都放一个数字 “1”，这个判断不可能为空，可以直接累加。
- count(字段)：
    - 如果这个字段为 not null，则读出字段，按行累加。
    - 如果这个字段为允许 null，在执行的时候，需要将值取出判断，如果不是 null 才累加。
- count(*)：不会取出全部字段，而是专门做了优化，按行累加。

综上，按照效率排序，count(字段) < count(主键 id) < count(1) ≈ count(\*)。所以，建议尽量使用count(\*)。

COUNT(*)计算表中总的行数，不管某列是否有数值或者为空值；COUNT(字段名)计算指定列下总的行数，计算时将忽略空值的行。MAX()和MIN()函数不仅适用于查找数值类型，也可应用于字符类型。
![image.png](/assets/img/mysql_count.png)

```sql
--使用 CASE...WHEN...THEN 语句实现行转列
SELECT userid,
SUM(CASE `subject` WHEN '语文' THEN score ELSE 0 END) as '语文',
SUM(CASE `subject` WHEN '数学' THEN score ELSE 0 END) as '数学',
SUM(CASE `subject` WHEN '英语' THEN score ELSE 0 END) as '英语',
SUM(CASE `subject` WHEN '政治' THEN score ELSE 0 END) as '政治' 
FROM tb_score 
GROUP BY userid
```

SUM() 是为了能够使用GROUP BY根据userid进行分组，因为每一个userid对应的subject="语文"的记录只有一条，所以SUM() 的值就等于对应那一条记录的score的值。假如userid ='001' and subject='语文' 的记录有两条，则此时SUM() 的值将会是这两条记录的和

```sql
-- 用 IF() 函数实现行转列
SELECT userid,
SUM(IF(`subject`='语文',score,0)) as '语文',
SUM(IF(`subject`='数学',score,0)) as '数学',
SUM(IF(`subject`='英语',score,0)) as '英语',
SUM(IF(`subject`='政治',score,0)) as '政治' 
FROM tb_score 
GROUP BY userid
```

**SQL注入：**
SQL注入的原理是将SQL代码伪装到输入参数中，传递到服务器解析并执行的一种攻击手法。
解决SQL注入：①严格的参数校验；②SQL预编译，在服务器启动时，MySQL Client把SQL语句的模板（变量采用占位符进行占位）发送给MySQL服务器，MySQL服务器对SQL语句的模板进行编译，编译之后根据语句的优化分析对相应的索引进行优化，在最终绑定参数时把相应的参数传送给MySQL服务器，直接进行执行

**将一张表的部分数据更新到另一张表：**

```sql
update b set b.col=a.col from a,b where a.id=b.id;
update b set b.col=a.col from b inner join a on a.id=b.id;
update b set b.col=a.col from b left Join a on b.id = a.id;
```

WHERE是一个约束声明，使用WHERE约束来自数据库的数据，WHERE是在结果返回之前起作用的，WHERE中不能使用聚合函数。
HAVING是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在HAVING中可以使用聚合函数。另一方面，HAVING子句中不能使用除了分组字段和聚合函数之外的其他字段。
从性能的角度来说，HAVING子句中如果使用了分组字段作为过滤条件，应该替换成WHERE子句。因为WHERE可以在执行分组操作和计算聚合函数之前过滤掉不需要的数据，性能会更好。

```sql
SELECT Customer,SUM(OrderPrice) FROM Orders
GROUP BY Customer
HAVING SUM(OrderPrice)<2000
```

**对数据库优化的理解：**
MySQL数据库优化是多方面的，原则是减少系统的瓶颈，减少资源的占用，增加系统的反应速度。例如，通过优化文件系统，提高磁盘I/O的读写速度；通过优化操作系统调度策略，提高MySQL在高负荷情况下的负载能力；优化表结构、索引、查询语句等使查询响应更快。
针对查询，我们可以通过使用索引、使用连接代替子查询的方式来提高查询速度。
针对慢查询，我们可以通过分析慢查询日志，来发现引起慢查询的原因，从而有针对性的进行优化。
针对插入，我们可以通过禁用索引、禁用检查等方式来提高插入速度，在插入之后再启用索引和检查。
针对数据库结构，我们可以通过将字段很多的表拆分成多张表、增加中间表、增加冗余字段等方式进行优化。

**优化MySQL的查询：**
使用索引：如果查询时没有使用索引，查询语句将扫描表中的所有记录。在数据量大的情况下，这样查询的速度会很慢。如果使用索引进行查询，查询语句可以根据索引快速定位到待查询记录，从而减少查询的记录数，达到提高查询速度的目的。
索引可以提高查询的速度，但并不是使用带有索引的字段查询时索引都会起作用。有几种特殊情况，在这些情况下有可能使用带有索引的字段查询时索引并没有起作用。

1. 使用LIKE关键字的查询语句在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用。
2. 使用多列索引的查询语句MySQL可以为多个字段创建索引。一个索引可以包括16个字段。对于多列索引，**生效的规则是：从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的索引没有起作用**
3. 使用OR关键字的查询语句查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。

**优化子查询：**
使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。
子查询虽然可以使查询语句很灵活，但执行效率不高。执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表。然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表。因此，子查询的速度会受到一定的影响。如果查询的数据量比较大，这种影响就会随之增大。
在MySQL中，可以使用**连接（JOIN）查询来替代子查询**。连接查询不需要建立临时表，其速度比子查询要快，如果查询中使用索引，性能会更好。

**插入数据才能更高效：**
对于MyISAM引擎的表，常见的优化方法如下：

1. 禁用索引。对于非空表，插入记录时，MySQL会根据表的索引对插入的记录建立索引。如果插入大量数据，建立索引会降低插入记录的速度。可以在插入记录之前禁用索引，数据插入完毕后再开启索引。对于空表批量导入数据，则不需要进行此操作，因为MyISAM引擎的表是在导入数据之后才建立索引的。
2. 禁用唯一性检查。插入数据时，MySQL会对插入的记录进行唯一性校验。这种唯一性校验也会降低插入记录的速度。为了降低这种情况对查询速度的影响，可以在插入记录之前禁用唯一性检查，等到记录插入完毕后再开启。
3. 使用批量插入。插入多条记录时，可以使用一条INSERT语句插入一条记录，也可以使用一条INSERT语句插入多条记录。使用一条INSERT语句的插入速度更快。
4. 使用LOAD DATA INFILE批量导入。当需要批量导入数据时，如果能用LOAD DATA INFILE语句，就尽量使用。因为LOAD DATA INFILE语句导入数据的速度比INSERT语句快。

对于InnoDB引擎的表，常见的优化方法如下：

1. 禁用唯一性检查。插入数据之前执行set unique_checks=0来禁止对唯一索引的检查，数据导入完成之后再运行set unique_checks=1。这个和MyISAM引擎的使用方法一样。
2. 禁用外键检查。插入数据之前执行禁止对外键的检查，数据插入完成之后再恢复对外键的检查。
3. 禁用自动提交。插入数据之前禁止事务的自动提交，数据导入完成之后，执行恢复自动提交操作。

**表中包含几千万条数据该怎么办？**

1. 优化SQL和索引；
2. 增加缓存，如memcached、redis；
3. 读写分离，可以采用主从复制，也可以采用主主复制；
4. 使用MySQL自带的分区表，这对应用是透明的，无需改代码，但SQL语句是要针对分区表做优化的；
5. 做垂直拆分，即根据模块的耦合度，将一个大的系统分为多个小的系统；
6. 做水平拆分，要选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表。

**MySQL的慢查询优化：**
优化MySQL的慢查询，可以按照如下步骤进行：
开启慢查询日志：MySQL中慢查询日志默认是关闭的，可以通过配置文件my.ini或者my.cnf中的log-slow-queries选项打开，也可以在MySQL服务启动的时候使用--log-slow-queries[=file_name]启动慢查询日志。
启动慢查询日志时，需要在my.ini或者my.cnf文件中配置long_query_time选项指定记录阈值，如果某条查询语句的查询时间超过了这个值，这个查询过程将被记录到慢查询日志文件中。
分析慢查询日志：直接分析mysql慢查询日志，利用explain关键字可以模拟优化器执行SQL查询语句，来分析sql慢查询语句。

常见慢查询优化：

1. 索引没起作用的情况
   - 在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用。
   - MySQL可以为多个字段创建索引。一个索引可以包括16个字段。对于多列索引，只有查询条件中使用了这些字段中的第1个字段时索引才会被使用。
   - 查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。
2. 优化数据库结构
   - 对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。
   - 对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。
3. 分解关联查询。很多高性能的应用都会对关联查询进行分解，就是可以对每一个表进行一次单表查询，然后将查询结果在应用程序中进行关联，很多场景下这样会更高效。
4. 优化LIMIT分页。当偏移量非常大的时候，例如可能是limit 10000,20这样的查询，这是mysql需要查询10020条然后只返回最后20条，前面的10000条记录都将被舍弃，这样的代价很高。优化此类查询的一个最简单的方法是尽可能的使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升。

**explain <=> describe**
使用EXTENED关键字，EXPLAIN语句将产生附加信息。执行该语句，可以分析EXPLAIN后面SELECT语句的执行情况，并且能够分析出所查询表的一些特征。下面对查询结果进行解释：

- id：SELECT识别符。这是SELECT的查询序列号。
- select_type：表示SELECT语句的类型。
- table：表示查询的表。
- type：表示表的连接类型。
- possible_keys：给出了MySQL在搜索数据记录时可选用的各个索引。
- key：是MySQL实际选用的索引。
- key_len：给出索引按字节计算的长度，key_len数值越小，表示越快。
- ref：给出了关联关系中另一个数据表里的数据列名。
- rows：是MySQL在执行这个查询时预计会从这个数据表里读出的数据行的个数。
- Extra：提供了与关联操作有关的信息。

```sql
EXPLAIN [EXTENDED] SELECT select_options
DESCRIBE SELECT select_options
```

**百万级别或以上的数据如何删除**
由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

- 先删除索引
- 再删除一些无用数据

## 8 MYSQL分区、分表、分库

**分区：**
当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率。**分区是将同一表中不同行的记录分配到不同的物理文件中，几个分区就有几个.idb文件**。

优点：

-  逻辑数据分割 
-  提高单一的写和读应用速度 
-  提高分区范围读查询的速度 
-  分割数据能够有多个不同的物理文件路径 
-  高效的保存历史数据

缺点：

- 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁 
-  一旦数据并发量上来，如果在分区表实施关联，就是一个灾难

**分区类型及操作**

- **RANGE分区**：基于属于一个给定连续区间的列值，把多行分配给分区。mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的。 按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，比如交易表啊，销售表啊等，可以根据年月来存放数据。可能会产生热点问题，大量的流量都打在最新的数据上了。 range 来分，好处在于说，扩容的时候很简单。 
- **LIST分区**：类似于按RANGE分区，每个分区必须明确定义。它们的主要区别在于，LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。 
- **HASH分区**：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表 
- **KEY分区**：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。

**分表：**
分表有两种分割方式，一种垂直拆分，另一种水平拆分。

- **垂直拆分** 垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。 
- **水平拆分(数据分片)** 单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。

水平分割的几种方法： 

- 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位） 
- 还可根据时间放入不同的表。 
- 按热度拆分 
- 根据ID的值放入对应的表

**分库：**
数据库集群环境后都是多台 slave，基本满足了读取操作；但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。
一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。

优点：

-  减少增量数据写入时的锁对查询的影响 
-  由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短

分表后主键自增问题怎么解决？
①需要一个表来专门创建id；②使用UUID的方式；③通过Redis队列完成创建（失败会返回失败的id）

## 9 其他

第一范式（1NF）：是指在关系模型中，数据库表的每一列都是不可分割的原子数据项。
第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）。
第三范式（3NF）：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）。

binlog（Binary Log）：二进制日志文件就是常说的binlog。二进制日志记录了MySQL所有修改数据库的操作，然后以二进制的形式记录在日志文件中，其中还包括每条语句所执行的时间和所消耗的资源，以及相关的事务信息。
默认情况下，二进制日志功能是开启的，启动时可以重新配置--log-bin[=file_name]选项，修改二进制日志存放的目录和文件名称。
redo log：重做日志用来实现事务的持久性，即事务ACID中的D。它由两部分组成：一是内存中的重做日志缓冲（redo log buffer），其是易失的；二是重做日志文件（redo log file），它是持久的。
undo log：重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要undo。因此在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。

MySQL主从同步：复制（replication）是MySQL数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。总体来说，replication的工作原理分为以下3个步骤：

1. 主服务器（master）把数据更改记录到二进制日志（binlog）中。
2. 从服务器（slave）把主服务器的二进制日志复制到自己的中继日志（relay log）中。
3. 从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性。

![image.png](/assets/img/mysql_lustre.png)
复制的工作原理如下图所示，其中从服务器有2个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是SQL线程，复制执行中继日志。

**关系型数据库**：将数据存储在表中的数据库，表和字段类型之间的关系有明确定义
**非关系型数据库：** 是一种数据结构化存储方法的集合，可以是文档或者键值对等，表和字段类型没有关系。比如文档、列式数据库、图数据库