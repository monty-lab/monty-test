---
layout: post
title: Redis
date: 2023-10-29 14:22 +0800
categories: [笔记]
tags: [Redis]
toc:  true
---

Redis（Remote Dictionary Server远程字典服务）是一个开源的支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。

Redis优缺点：

- 读写性能优异
- 支持数据持久化，支持AOF和RDB两种持久化方式
- 支持事务，Redis的所有操作都是原子性的，Redis还支持对几个操作合并后的原子性操作；
- 数据结构丰富
- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离

缺点：

- 数据库容量收到物理内存的限制，不能用作海量数据的高性能读写
- Redis不具备自动容错和恢复功能，主机从机宕机都会导致前端部分读写请求失败
- 主机宕机，宕机前数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；
- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

## 1 Redis为什么快

Redis完全基于内存操作，CPU不是redis的瓶颈，redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会称为瓶颈，使用单线程也能并发的处理客户端的请求：

- Redis完全基于内存
- 数据结构简单，对数据的操作也简单
- 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗
- 使用多路复用IO模型，非阻塞IO
- 使用的底层模型不同，Redis直接自己构建了VM机制



### 1.1 Redis线程模型

![](/assets/img/redis_io.png)

Redis基于 Reactor 模式开发了自己**网络事件处理器**。Redis-client在操作时，会产生不同事件类型的Socket。在服务端有一段I/O多路复用程序（epoll），将其置于队列之中。文件事件分配器（单线程）依次去队列中取，转发到不同的事件处理器中。

> Reactor模式应用于同步I/O的场景。Reactor中读操作的具体步骤如下：
> （1）应用程序注册读就需事件和相关联的事件处理器
> （2）事件分离器等待事件的发生
> （3）当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器
> （4）事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理

Redis4.0添加多线程特性： 要删除一个大 key 时，del bigkey会一直阻塞，等待删除完成，才能继续操作，会导致Redis主线程卡顿。引入了 **惰性删除** ，把某些费时较高删除操作，从redis主线程剥离让BIO子线程来处理，极大地减少主线阻塞时间。从而减少删除导致性能和稳定性问题。

其他子线程： 快照生成、AOF重写

![](/assets/img/redis_multi_thread.png)

Redis6/7多线程： 将主线程的IO读写任务拆分给一组独立的线程去执行，这样就可以使用多个socket的读写进行并行化了，采用多路IO复用技术可以让单个线程高效处理多个连接请求，将最耗时的socket的读取、请求解析、写入等单独执行，剩下的命令执行仍然由主线程串行执行并和内存的数据交换。



## 2 数据结构

Redis在互联网产品中使用的场景：

1）String：缓存、限流、分布式锁、计数器、分布式 Session 等。

2）Hash：用户信息、用户主页访问量、组合查询等。

3）List：简单队列、关注列表时间轴。

4）Set：赞、踩、标签等。

5）ZSet：排行榜、好友关系链表。

### 2.1 String

Redis中所有的key都是字符串，这些字符串是通过一个名为**简单动态字符串（SDS）** 的抽象数据类型实现的。SDS：

- 常数复杂度获取字符串长度
- 杜绝缓冲区溢出
- 减少修改字符串的内存重新分配次数
- 二进制安全
- 兼容部分 C 字符串函数

![](/assets/img/redis_sds_c.png)

```cpp
struct sdshdr{
     //记录buf数组中已使用字节的数量，等于SDS保存字符串的长度
     int len;
     //记录 buf 数组中未使用字节的数量
     int free;
     //字节数组，用于保存字符串
     char buf[];
}
```

![](/assets/img/redis_sds.png)

### 2.2 Hash

Redis Hash内部实现是“数组+链表”的方式

解决Hash冲突：Redis通过**链式哈希**解决冲突，同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能，所以Redis使用了两个全局哈希表用于rehash操作。

扩容和收缩：①每次扩展根据原哈希表已使用的空间扩大一倍创建另一个哈希表。每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。②重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。③释放原哈希表的内存空间

触发扩容条件：服务器目前没有执行BGSAVE（持久化）命令或者BGREWRITEAOF命令，并且负载因子等于 1。服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且负载因子等于 5。负载因子 = 哈希表已保存节点数量 / 哈希表大小

渐近式rehash：扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。

![](/assets/img/redis_hash.png)

### 2.3 List
```cpp
typedef struct list{
     listNode *head;
     listNode *tail;
     //链表所包含的节点数量
     unsigned long len;
     //节点值复制函数
     void (*copy) (void *ptr);
     //节点值释放函数
     void (*free) (void *ptr);
     //节点值对比函数
     int (*match) (void *ptr,void *key);
}list;

typedef  struct listNode{
       struct listNode *prev;
       struct listNode *next;
       void *value;  
}listNode
```
### 2.4 Set

### 2.5 Zset

![](/assets/img/redis_zset.png)

所有的元素都会在L0层的链表中，根据分数进行排序，同时会有一部分节点有机会被抽取到L1层中，作为一个稀疏索引，同样L1层中的索引也有一定机会被抽取到L2层中，组成一个更稀疏的索引列表。

跳表查找：

![](/assets/img/redis_zset_find.png)

比如上图，想要查询分数为66的元素，首先在L2层的索引找，66位于25和85中间，再去L1层的索引去找，类推。

跳表插入：首先找到插入的位置，然后完成插入。结点增多了，索引也相应增加，出现两个索引之间结点过多的情况。跳表是通过一个随机函数来维护这个平衡的，当我们向跳表中插入数据的的时候，我们可以选择同时把这个数据插入到索引里，需要随机函数，来决定我们插入到哪一级的索引中。

跳表删除：自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层

## 3 Redis内存淘汰策略和数据过期

当Redis内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换（swap）。交换会让Redis的性能急剧下降，Redis提供了配置参数**maxmemory**来限制内存超出期望大小，当实际内存超出**maxmemory**时，Redid提供了几种可选策略：

- **noeviction** 不会继续服务写请求（DEL请求可以继续服务），读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略；
- **volatile-lru** 尝试淘汰设置了过期时间的key，最少使用的key优先被淘汰。没有设置过期时间的key不会被淘汰，这样可以保证需要持久化的数据不会突然丢失；
- **volatile-ttl** 跟上面一样，除了淘汰的策略不是LRU，而是key的剩余寿命ttl的值，ttl越小越优先被淘汰；
- **volatile-random** 跟上面一样，不过淘汰的key是过期key集合中随机的key；
- **allkeys-lru** 区别于volatile-lru，这个策略要淘汰的key对象是全体的key集合，而不只是过期的key集合。这意味着没有设置过期时间的key也会被淘汰；
- **allkeys-random** 跟上面一样，不过淘汰的策略是随机的key；

Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理：①`expire key time`②`setex(String key, int seconds, String value)`

- 定时删除；每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。
- 惰性删除；只有当访问一个key时，才会判断该key是否已过期，过期则清除。
- 定期删除；对指定个数库的每一个库随机删除小于等于指定个数个过期key

<font color='red'> Redis采用的是定期删除和惰性删除策略 </font>

## 4 Redis缓存

**为什么要用Redis/为什么要用缓存**：①高性能；第一次访问数据库中的数据，过程会比较慢，因为是从硬盘上读取的。将访问的数据存在缓存中，操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变之后，同步改变缓存中响应的数据即可。②高并发；直接操作缓存能够承受的请求数量是远大于直接访问数据库的

Redis缓存满了是先删后写还是先写后删？

- 先删除缓存后写DB，产生脏数据的概率较大。比如两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。
- 先写DB后删缓存，产生脏数据的概率较小，但是会出现一致性的问题；

解决：①缓存设置过期时间，实现一致性②使用 Cannel 等中间件监听 binlog 进行异步更新；

**缓存和数据库一致性问题：** 分布式环境下容易出现缓存和数据库间数据一致性问题，如果项目对缓存的要求是强一致性的，那么就不要用缓存。我们只能采用适当的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括合适的缓存更新策略，更新数据库后及时更新缓存、缓存失败时增加重试机制。

**Redis雪崩：** 缓存都是定时任务去刷新，或者查不到之后更新缓存的；如果缓存Key同一时间大面积失效，瞬间Redis跟没有一样，那这个数量级别的请求直接达到数据库上几乎是灾难性的

处理方法：①在批量往存数据的时候，把每个Key的失效时间都加随机值，这样可以保证数据不会在同一时间大面积失效。`setRedis（key, value, time+Math.random()*10000）;`②如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效。③设置热点数据永不过期，有更新操作就更新缓存

**缓存穿透和击穿：** 缓存穿透是指缓存和数据库都没有的数据，而用户（黑客）不断发起请求；缓存击穿跟是指某个Key非常热点，在不停地扛着大量请求，大并发集中地对这个点进行访问，当这个Key在失效地瞬间，持续地大并发直接落到了数据库上。

解决方法：①缓存击穿可以在接口层增加校验，比如用户鉴权、参数校验、不合法地校验直接return，比如id做基础校验，id<=0直接拦截；②布隆过滤器(Bloom Filter)利用高效地数据结构和算法快速判断Key是否在数据库中，不存在return，存在就去查DB刷新KV再return；③缓存击穿的话，设置热点数据永不过期，再加上互斥锁

**缓存预热：** 缓存预热指系统上线后，将相关的缓存数据直接加载到Redis中，这样就可以避免在用户请求时，先查询数据库，然后再将数据缓存的问题。

解决方法：①直接写个缓存刷新页面，系统上线时手动将缓存数据加载；②定时刷新缓存

**缓存降级：** 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

- 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
- 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
- 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
- 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。

## 5 持久化

Redis为了保证效率，数据存储在了内存中，但是会周期性地把更新的数据写入磁盘或者把修改操作写成追加的记录文件中，以保证数据的持久化。

Redis的持久化策略有两种：

- RDB(Redis database)：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略；
- AOF(Append Only File)：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。

Redis默认是快照RDB的持久化方式。当Redis重启的时候，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。甚至可以关闭持久化功能，让数据只在服务器运行时保存。

RDB和AOF的区别

1. RDB是一次全量备份，AOF日志是连续的增量备份；
2. RDB是内存数据的二进制序列化形式，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本；

### 5.1 RDB工作原理

当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉，这样的好处是可以copy-on-write。

优点：

- RDB 文件紧凑，全量备份，非常适合用于进行备份和灾难恢复
- 生成 RDB 文件时支持异步处理，主进程不需要进行任何磁盘IO操作
- RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快

缺点：RDB快照是一次全量备份，在快照持久化期间修改的数据不会被保存，可能丢失数据。

### 5.2 AOF工作原理
redis每执行一个修改数据的命令，都会把它添加到AOF文件中，当redis重启时，将会读取AOF文件进行重放，恢复到redis关闭前的最后时刻。

AOF 也有三种触发方式：1）每修改同步 always； 2）每秒同步 everysec； 3）不同no：从不同步。

优点：

- AOF数据安全，一般AOF隔1秒通过一个后台线程执行一次 fsync 操作
- AOF日志文件没有任何磁盘寻址的开销，写入性能非常高
- AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写

缺点：

- 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大
- 数据集很大时，启动效率比RDB低

Redis AOF重写：①进程内超时的数据不在写入文件；②会删除旧的AOF中无效命令，只保留最终数据的写入命令；③将多条命令合并为一个

| **命令** | **RDB** | **AOF** |
| --- | --- | --- |
| 启动优先级 | 低 | 高 |
| 体积 | 小 | 大 |
| 恢复速度 | 快 | 慢 |
| 数据安全性 | 丢数据 | 取决于刷盘策略 |

## 6 Redis事务

Redis事务是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

**MULTI命令**：用于开启事务。MULTI执行后，Client可以继续向服务器发送任意多条命令，这些命令会存放到一个队列中，当EXEC命令调用后，所有队列中的命令才会被执行。

**EXEC命令**：执行所有事务块的命令，可以理解为提交事务。按命令的执行顺序，返回事务中所有命令的返回值。当操作被打断时，返回空值（nil）。

**DISCARD命令**：用于清空事务队列，并放弃执行事务。Client从事务状态中退出。

**WATCH命令**：是一个乐观锁，可以为Redis提供CAS操作。可以监控一个或多个键，一旦其中有一个键被修改或删除，之后的事务就不执行，监控一直持续到EXEC命令。

**UNWATCH命令**：用于取消WATCH命令对所有key的监控。

Redis的事务具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有持久性。

Redis事务支持隔离性吗：Redis是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。

Redis事务保证原子性吗，支持回滚吗：Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

**可以使用客户端加锁的方式保证Redis API的原子性**

## 7 Redis集群

Redis集群搭建模式：主从模式、哨兵模式、Cluster集群模式

### 7.1 Redis哨兵集群

随着负载不断上升，主节点服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。**Sentinel**（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器选举出新的主服务器。

sentinel(哨兵机制)其实就是一个运行在特殊模式下的Redis服务器。

#### 7.1.1 监控

监控指的就是哨兵进程运行时，它会周期性地心跳检测，检测所有主从服务器是否正常运行。心跳检测方式为周期性向主从服务器发送PING命令，主从服务器在规定时间内响应哨兵进程

#### 7.1.2 故障转移

若主服务器处于下线状态时，哨兵进程会进行故障转移，也就是重新选主。选主就是会从其所属的多个从服务器中选举一个服务器作为新的主服务器，来提供服务。选举成功后，哨兵进程让已下线主服务器属下的所有从服务器去复制新的主服务器，这一动作会通过向从服务器发送SLAVEOF命令来实现。

#### 7.1.3 获取信息

sentinel(哨兵)进程默认会以每隔10秒一次的频率，通过命令连接向被连接的主从服务器发送INFO命令，并通过分析INFO命令返回的数据来获取主服务器的当前信息以及所属从服务器信息。

#### 7.1.4 哨兵间通信

哨兵节点不会直接与其他哨兵节点建立连接，而是首先会和主库建立起连接，然后向一个名为"_sentinel_:hello"频道发送自己的信息（IP+port），哨兵节点的互通是通过订阅指定的频道来进行的，而不是直接与其他sentinel节点建立起连接。

同时客户端可以从哨兵订阅所有事件，这样客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控主从库切换过程中发生的各个重要事件。

#### 7.1.5 主观下线和客观下线 

1. 主观下线：任何一个哨兵都是可以监控探测，并作出Redis节点主观下线的判断；
2. 客观下线：有哨兵集群共同决定Redis节点是否下线；

#### 7.1.6 哨兵集群的选举

判断完主库下线后，由哪个哨兵节点来执行主从切换呢？这里就需要哨兵集群的选举机制了。

为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及共识问题（即选举问题）；同时故障的转移和通知都只需要一个主的哨兵节点就可以了。

哨兵的选举机制其实很简单，就是一个Raft选举算法： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举

任何一个想成为 Leader 的哨兵，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

#### 7.1.7 新主库的选出

过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点

选择salve-priority从节点优先级最高（redis.conf）的

选择复制偏移量最大，只复制最完整的从节点

#### 7.1.8 故障的转移（Leader哨兵执行）

1. 将新的主节点脱离原从节点，升级主节点

2. 将从节点指向新的主节点

3. 通知客户端主节点已更换

4. 将原主节点（oldMaster）变成从节点，指向新的主节点

### 7.2 主从模式

主从复制可以根据需要分为**全量同步**的**增量同步**两种方式。

Redis全量复制一般发生在slave的初始阶段，这时slave需要将master上的数据都复制一份，具体步骤：

1. slave 连接 master，发送 SYNC 命令
2. master接到SYNC命令后执行 BGSAVE 命令生产 RDB 文件，并使用缓冲区记录此后执行的所有写命令
3. master 执行完 BGSAVE 后，向所有的 slave 发送快照文件，并在发送过程中继续记录执行的写命令
4. slave 收到快照后，丢弃所有的旧数据，载入收到的数据
5. master 快照发送完成后就会开始向 slave 发送缓冲区的写命令；
6. slave 完成对快照的载入，并开始接受命令请求，执行来自 master 缓冲区的写命令；
7. slave 完成上面的数据初始化后就可以开始接受用户的读请求了。

增量复制实际上就是在 slave 初始化完成后开始正常工作时 master 发生写操作同步到 slave 的过程。增量复制的过程主要是 master 每执行一个写命令就会向 slave 发送相同的写命令，slave 接受并执行写命令，从而保持主从一致。

Redis同步策略：主从同步刚连接的时候进行全量同步，全量同步结束后开始增量同步。增量同步如果失败则会要求slave 进行全量同步；避免多个slave同时恢复重启的情况。

Redis主从模式：主从实例部署在不同的物理服务器上，可以实现同时对外提供服务和读写分离策略。

无磁盘复制优化：主Redis生成的RDB文件不落在磁盘上，而是直接在内存中通过网络发送;而从Redis也不是将RDB下载到磁盘，而是直接获取在内存中

Redis分片集群：Redis会根据key的有效部分计算插槽值，然后把数据存储到对应的插槽中去。数据key不是与节点绑定，而是与插槽绑定。Reids会将这些插槽分配给各个节点，当我们读取或者写入数据时，会根据数据的key计算出插槽，然后到对应的节点上进行操作。

## 8 Redis分布式锁

分布式锁，即分布式系统中的锁。在单体应用中我们通过锁解决的是控制共享资源访问的问题，而分布式锁，就是解决了分布式系统中控制共享资源访问的问题。

分布式锁的实现方式：

- 基于数据库实现分布式锁
- 基于reids实现分布式锁

### 8.1 基于数据库实现分布式锁

基于数据库的锁实现也有两种方式，一是基于数据库表的增删，另一种是基于数据库排他锁。

1、基于数据库表的增删：

基于数据库表增删是最简单的方式，首先创建一张锁的表主要包含下列字段：文件的全路径名+方法名，时间戳等字段。

具体的使用方式：当需要锁住某个方法时，往该表中插入一条相关的记录。文件的全路径名+方法名是有唯一性约束的，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。执行完毕之后，需要delete该记录。

2、基于数据库排他锁：

基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作：

```sql
select * from lock where lock_name=xxx for update;
```

在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。获得排它锁的线程即可获得分布式锁

### 8.2 基于reids实现分布式锁

>redis命令说明：
>（1）setnx命令：set if not exists，当且仅当 key 不存在时，将 key 的值设为value。若给定的 key 已经存在，则 SETNX 不做任何动作。
>返回1，说明该进程获得锁，将 key 的值设为 value
>返回0，说明其他进程已经获得了锁，进程不能进入临界区。
>命令格式：setnx lock.key lock.value
>
>（2）get命令：获取key的值，如果存在，则返回；如果不存在，则返回nil
>命令格式：get lock.key
>
>（3）getset命令：该方法是原子的，对key设置newValue这个值，并且返回key原来的旧值。
>命令格式：getset lock.key newValue
>
>（4）del命令：删除redis中指定的key
>命令格式：del lock.key

#### 8.2.1 基于set命令的分布式锁

1、加锁：使用setnx进行加锁，当该指令返回1时，说明成功获得锁

2、解锁：当得到锁的线程执行完任务之后，使用del命令释放锁，以便其他线程可以继续执行setnx命令来获得锁

存在的问题：假设线程获取了锁之后，在执行任务的过程中挂掉，来不及显示地执行del命令释放锁，那么竞争该锁的线程都会执行不了，产生死锁的情况。

3、设置锁超时时间：setnx 的 key 必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一定时间后自动释放。可以使用expire命令设置锁超时时间

存在问题：setnx 和 expire 不是原子性的操作，假设某个线程执行setnx 命令，成功获得了锁，但是还没来得及执行expire 命令，服务器就挂掉了，这样一来，这把锁就没有设置过期时间了，变成了死锁，别的线程再也没有办法获得锁了。

4、使用set命令加锁并设置锁过期时间：

命令格式：set <lock.key> <lock.value> nx ex <expireTime>

存在问题：

① 假如线程A成功得到了锁，并且设置的超时时间是 30 秒。如果某些原因导致线程 A 执行的很慢，过了 30 秒都没执行完，这时候锁过期自动释放，线程 B 得到了锁。

② 随后，线程A执行完任务，接着执行del指令来释放锁。但这时候线程 B 还没执行完，线程A实际上删除的是线程B加的锁。

5、锁续期

虽然步骤4避免了线程A误删掉key的情况，但是同一时间有 A，B 两个线程在访问代码块，仍然是不完美的。怎么办呢？我们可以让获得锁的线程开启一个守护线程，用来给快要过期的锁“续期”。

假设线程A执行了29 秒后还没执行完，这时候守护线程会执行 expire 指令，为这把锁续期 20 秒。守护线程从第 29 秒开始执行，每 20 秒执行一次。

#### 8.2.2 基于setnx、get、getset的分布式锁

（1）setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁，转向步骤(2)

（2）get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向步骤(3)

（3）计算新的过期时间 newExpireTime=当前时间+锁超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime

（4）判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。

（5）在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行del命令释放锁（释放锁之前需要判断持有锁的线程是不是当前线程）；如果大于锁设置的超时时间，则不需要再锁进行处理。

#### 8.2.3 基于RedLock的分布式锁

![](/assets/img/redis_redlock.png)

现在假设有5个Redis主节点(大于3的奇数个)，这样基本保证他们不会同时都宕掉，获取锁和释放锁的过程中，客户端会执行以下操作：

（1）获取当前Unix时间，以毫秒为单位，并设置超时时间TTL

TTL 要大于 正常业务执行的时间 + 获取所有redis服务消耗时间 + 时钟漂移

（2）依次尝试从5个实例，使用相同的key和具有唯一性的value获取锁，当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间TTL，这样可以避免客户端死等。比如：TTL为5s，设置获取锁最多用1s

（3）客户端 获取所有能获取的锁后的时间 减去 第(1)步的时间，就得到锁的获取时间。锁的获取时间要小于锁失效时间TTL，并且至少从半数以上的Redis节点取到锁，才算获取成功锁

（4）如果成功获得锁，key的真正有效时间 = TTL - 锁的获取时间 - 时钟漂移

（5）如果获取锁失败（没有在半数以上实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁

（6）失败重试：当client不能获取锁时，应该在随机时间后重试获取锁；同时重试获取锁要有一定次数限制

RedLock性能及崩溃恢复的相关解决方法：

由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。前面我们说的主从架构下存在的安全性问题，在RedLock中已经不存在了，但如果有节点发生崩溃重启，还是会对锁的安全性有影响的，具体的影响程度跟Redis持久化配置有关：

（1）如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁的排他互斥性；

（2）如果启动AOF永久化存储，举例：当我们重启redis后，由于redis过期机制是按照unix时间戳走的，所以在重启后，然后会按照规定的时间过期，不影响业务；但是由于AOF同步到磁盘的方式默认是每秒一次，如果在一秒内断电，会导致数据丢失，立即重启会造成锁互斥性失效；但如果同步磁盘方式使用Always(每一个写命令都同步到硬盘)造成性能急剧下降；所以在锁完全有效性和性能方面要有所取舍；

（3）为了有效解决既保证锁完全有效性和性能高效问题：antirez又提出了“延迟重启”的概念，redis同步到磁盘方式保持默认的每秒1次，在redis崩溃单机后（无论是一个还是所有），先不立即重启它，而是等待TTL时间后再重启，这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响，缺点是在TTL时间内服务相当于暂停状态